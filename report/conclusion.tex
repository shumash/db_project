\section{Conclusion}

\begin{edit}
Summarize paper contributions
\end{edit}


\input{apps.tex}


\subsection{Future Extensions}
\label{sec:futureext}

In this paper we considered a simple implementation of a patch-based image database compression scheme, where the images and patches were square and of fixed sizes. Patches were sampled in a regular, non-overlapping grid from each image.  Alternative approaches include more flexible, context-aware, patch-sampling techniques. For instance, the patch granularity for sampling large homogenous sky and field regions may be different from the one used for sampling highly-textured regions like objects and structures (trees, buildings, people, etc.). Similarly, patches that do not cross object boundaries are likely to lead to less artifacts in future reconstructions. For this, approaches like Selective Search \cite{UijlingsIJCV2013} that localize image regions likely to contain objects, may prove promising for sampling patches.

If patches were different sizes, then one of a number of extensions to the system would be required - for instance, (1) a patch transformation scheme, or (2) a hierarchical patch dictionary. A patch transformation scheme would permit each patch to be transformed (in a simple way - e.g. via rescaling) to match another patch with the same appearance but different (scale) parameters. For instance, a small patch in one image may be sufficient to account for a much larger part of another image, and rather than storing many separate patches of different sizes, we would benefit from quickly applying transformations to existing dictionary patches. To implement this system would require storing, for each image location, not only a pointer to a patch in the patch dictionary but also a transformation (e.g. a set of scaling parameters). Naturally, the cost function (to weigh the benefits of such a scheme vs storing the original images or even equally-sized patches) would need to take into account (a) the extra parameters stored along with each image location, and (b) the reconstruction time overhead for patch transformation. With large enough datasets, this approach may be effective at eliminating redundancy.

Another approach, building hierarchical patch dictionaries, may speed up the patchifying and subsequent reconstruction of an image, by offering a top-down approach. If larger patches match, there is no need to parse the image at a finer-grained scale. Only if large patches do not properly account for the structure in an image, would it be necessary to go to a finer-grained patch size. Note that small patches could be composed into larger patches, via a hierarchy, so that if large-patch matches are not found, descending down the patch hierarchy of the best-matching large patches would make it possible to find a match at a lower granularity. This scheme would be less flexible than the patch transformation scheme, but may prove to be more efficient. 

